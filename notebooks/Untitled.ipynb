{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mobile-devices",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score, recall_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "\n",
    "def split_data(data: pd.DataFrame) -> Tuple:\n",
    "    \"\"\"\n",
    "    Splits data into train and test splits.\n",
    "    Args:\n",
    "        data: DataFrame containing the features and target to split\n",
    "        parameters: Dictionary of parameters to split the data using sklearn.train_test_split\n",
    "    Returns:\n",
    "        Tuple containing the splited data.\n",
    "    \"\"\"\n",
    "\n",
    "    X = data.drop('stroke', axis=1)\n",
    "    y = data.stroke\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size = 0.3,\n",
    "        random_state = 42,\n",
    "        stratify=y\n",
    "    )\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_model(X_train: pd.DataFrame, y_train: pd.Series) -> RandomizedSearchCV:\n",
    "    \"\"\"\n",
    "    Use Randomized Search to tune the Gradient Boost hyperparameters and train model\n",
    "\n",
    "    Args:\n",
    "        X_train, y_train : training data\n",
    "    Return:\n",
    "        RandomizedSearchCV with the model parameters.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    #oversample data\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "    params = {\n",
    "    'learning_rate': [0.05,0.01,0.0001],\n",
    "    'num_leaves': [90,140,200],\n",
    "    'boosting_type' : ['gbdt'],\n",
    "    'objective' : ['binary'],\n",
    "    'max_depth' : [3,4,5,6,7,8],\n",
    "    'random_state' : [42], \n",
    "    'colsample_bytree' : [0.5,0.6,0.7,0.8,1.0],\n",
    "    'subsample' : [0.5,0.6,0.7,0.8,1.0],\n",
    "    'min_split_gain' : [0.01],\n",
    "    'min_data_in_leaf':[10],\n",
    "    'metric':['auc']\n",
    "    }\n",
    "    clf = lgb.LGBMClassifier()\n",
    "    RSCV = RandomizedSearchCV(clf,params,verbose=3,cv=10,n_jobs = -1,n_iter=10)\n",
    "    RSCV.fit(X_train_res,y_train_res)\n",
    "    return RSCV\n",
    "\n",
    "\n",
    "\n",
    "def evaluate_model(classifier: RandomizedSearchCV, X_test: pd.DataFrame, y_test: pd.Series) -> None:\n",
    "    \"\"\"\n",
    "    Calculates and logs the f1 score and recall.\n",
    "    Args:\n",
    "        classifier: Trained LGBMClassifier\n",
    "        X_test, y_test: Test_data for evaluation\n",
    "    \"\"\"\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    print ('f1_score: ', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "promising-optics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/03_primary/preprocessed_stroke_data.csv')\n",
    "X = df.drop('stroke', axis=1)\n",
    "y = df.stroke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "accomplished-taxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE()\n",
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "accredited-anatomy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "protected-general",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\arthu\\anaconda3\\envs\\stroke_project\\lib\\site-packages\\sklearn\\model_selection\\_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.91827434 0.90953662 0.86070266 0.83551974 0.87355349        nan\n",
      " 0.86070266 0.87123987 0.87123987 0.86789994]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=GradientBoostingClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'learning_rate': [0.05, 0.01, 0.0001],\n",
       "                                        'max_depth': [1, 2, 3, 4],\n",
       "                                        'min_samples_split': [1, 2, 3, 4],\n",
       "                                        'n_estimators': [90, 140, 200],\n",
       "                                        'warm_start': [False, True]},\n",
       "                   scoring='recall', verbose=3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "        'learning_rate': [0.05, 0.01, 0.0001],\n",
    "        'n_estimators': [90, 140, 200],\n",
    "        'min_samples_split': [1, 2, 3, 4],\n",
    "        'max_depth' : [1, 2, 3, 4],\n",
    "        'warm_start': [False, True]\n",
    "    }\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "RSVC = RandomizedSearchCV(\n",
    "        clf,\n",
    "        params,\n",
    "        verbose=3,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        n_iter=10,\n",
    "        scoring = 'recall'\n",
    ")\n",
    "\n",
    "RSVC.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "returning-butter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       975\n",
      "           1       0.94      0.90      0.92       970\n",
      "\n",
      "    accuracy                           0.93      1945\n",
      "   macro avg       0.93      0.93      0.93      1945\n",
      "weighted avg       0.93      0.93      0.93      1945\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred=rsvc.predict(X_test)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-balloon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
